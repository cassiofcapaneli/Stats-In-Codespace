{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e3f6bf",
   "metadata": {},
   "source": [
    "# Distribuições de Probabilidade e Amostragem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3800c834",
   "metadata": {},
   "source": [
    "## Probabilidade de alguém ser usuário de uma operadora de telefonia\n",
    "\n",
    "Qual é a probabilidade de uma pessoa no Brasil ser cliente da VIVO, CLARO ou TIM?\n",
    "\n",
    "Fonte: https://sistemas.anatel.gov.br/anexar-api/publico/anexos/download/44aaef993685036f18cab2ea0b4561e2\n",
    "\n",
    "Sendo que o percentual do mercado já foi calculado, iremos apenas normalizar o percentual para somar 1.\n",
    "\n",
    "Se considerarmos a população do país de 213.421.037 habitantes (https://www.ibge.gov.br/), podemos multiplicar a probabilidade pela quantidade total de habitantes e inferir a quantidade de usuários de determinada operadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e32bc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Operadora de telefonia  Pct mercado Período       P\n",
      "1                    VIVO        38.50  2T2025  0.3850\n",
      "3                   CLARO        32.52  2T2025  0.3252\n",
      "5                     TIM        23.40  2T2025  0.2340\n",
      "7                   ALGAR         1.68  2T2025  0.0168\n",
      "9                  Datora         1.13  2T2025  0.0113\n",
      "11                   SURF         0.93  2T2025  0.0093\n",
      "13             Next Level         0.42  2T2025  0.0042\n",
      "15              Teleports         0.32  2T2025  0.0032\n",
      "17               BRISANET         0.09  2T2025  0.0009\n",
      "19                   VERO         0.08  2T2025  0.0008\n",
      "21               UNIFIQUE         0.06  2T2025  0.0006\n",
      "23                  LIGGA         0.01  2T2025  0.0001\n",
      "Probabilidade total deve somar 1: 0.9914000000000002\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo CSV\n",
    "csv_path = 'Aula2/julio/Operadoradetelefonia-Pctmercado-Perodo.csv'\n",
    "\n",
    "# Lê o CSV em um DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Adiciona a coluna \"P\" como probabilidade (percentual dividido por 100)\n",
    "df['P'] = df['Pct mercado'] / 100\n",
    "\n",
    "# Exibe o DataFrame resultante\n",
    "# print(df)\n",
    "\n",
    "# Filtra apenas pelo período \"2T2025\"\n",
    "filtered_df = df[df['Período'] == '2T2025']\n",
    "print(filtered_df)\n",
    "\n",
    "# Some todas as probabilidades de filtered_df\n",
    "total_probability = filtered_df['P'].sum()\n",
    "print(f'Probabilidade total deve somar 1: {total_probability}')\n",
    "\n",
    "# Salve o DataFrame filtrado em um novo CSV\n",
    "filtered_csv_path = 'Aula2/julio/Operadoradetelefonia-Pctmercado-2T2025.csv'\n",
    "filtered_df.to_csv(filtered_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f589fd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Operadora de telefonia  Pct mercado Período       P  Estimated Users\n",
      "0                    VIVO        38.50  2T2025  0.3850     8.216710e+07\n",
      "1                   CLARO        32.52  2T2025  0.3252     6.940452e+07\n",
      "2                     TIM        23.40  2T2025  0.2340     4.994052e+07\n",
      "3                   ALGAR         1.68  2T2025  0.0168     3.585473e+06\n",
      "4                  Datora         1.13  2T2025  0.0113     2.411658e+06\n",
      "5                    SURF         0.93  2T2025  0.0093     1.984816e+06\n",
      "6              Next Level         0.42  2T2025  0.0042     8.963684e+05\n",
      "7               Teleports         0.32  2T2025  0.0032     6.829473e+05\n",
      "8                BRISANET         0.09  2T2025  0.0009     1.920789e+05\n",
      "9                    VERO         0.08  2T2025  0.0008     1.707368e+05\n",
      "10               UNIFIQUE         0.06  2T2025  0.0006     1.280526e+05\n",
      "11                  LIGGA         0.01  2T2025  0.0001     2.134210e+04\n",
      "+82 bilhões de usuários da VIVO no Brasil\n"
     ]
    }
   ],
   "source": [
    "# Lê o CSV filtrado em um novo DataFrame\n",
    "df = pd.read_csv(filtered_csv_path)\n",
    "\n",
    "# crie uma nova coluna \"Estimated Users\" que multiplica a probabilidade \"P\" pela população total do Brasil (213421037)\n",
    "population_brazil = 213421037\n",
    "df['Estimated Users'] = df['P'] * population_brazil\n",
    "print(df)\n",
    "print('+82 bilhões de usuários da VIVO no Brasil')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03317fb",
   "metadata": {},
   "source": [
    "\n",
    "No SGBD clickhouse, criar um DB IBGE\n",
    "\n",
    "https://clickhouse.com/docs/knowledgebase/importing-geojason-with-nested-object-array#question\n",
    "https://sidra.ibge.gov.br/home/pnadct/brasil\n",
    "https://www.ibge.gov.br/geociencias/organizacao-do-territorio/estrutura-territorial/26565-malhas-de-setores-censitarios-divisoes-intramunicipais.html\n",
    "\n",
    "\n",
    "- carregar shape (geojson)\n",
    "- fazer operações geoespacias\n",
    "- fazer JOIN e mostrar distribuições"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66de7a3",
   "metadata": {},
   "source": [
    "### Descomprimir e mover para a pasta de leitura do clickhouse\n",
    "\n",
    "```bash\n",
    "sudo mv BR_Municipios_2024.geojson /var/lib/clickhouse/user_files\n",
    "```\n",
    "\n",
    "Depois de entrar no clickhouse-client:\n",
    "\n",
    "```sql\n",
    "DESCRIBE TABLE file('BR_Municipios_2024.geojson', 'JSON')\n",
    "```\n",
    "\n",
    "Vemos:\n",
    "```bash\n",
    "DESCRIBE TABLE file('BR_Municipios_2024.geojson', 'JSON')\n",
    "\n",
    "Query id: 69b90589-8b43-4dbf-b461-b98de6c61636\n",
    "\n",
    "Row 1:\n",
    "──────\n",
    "name:               type\n",
    "type:               Nullable(String)\n",
    "default_type:       \n",
    "default_expression: \n",
    "comment:            \n",
    "codec_expression:   \n",
    "ttl_expression:     \n",
    "\n",
    "Row 2:\n",
    "──────\n",
    "name:               name\n",
    "type:               Nullable(String)\n",
    "default_type:       \n",
    "default_expression: \n",
    "comment:            \n",
    "codec_expression:   \n",
    "ttl_expression:     \n",
    "\n",
    "Row 3:\n",
    "──────\n",
    "name:               features\n",
    "type:               Array(Tuple(\n",
    "    geometry Tuple(\n",
    "        coordinates Array(Array(Array(Array(Nullable(Float64))))),\n",
    "        type Nullable(String)),\n",
    "    properties Tuple(\n",
    "        AREA_KM2 Nullable(Float64),\n",
    "        CD_CONCU Nullable(String),\n",
    "        CD_MUN Nullable(String),\n",
    "        CD_REGIA Nullable(String),\n",
    "        CD_RGI Nullable(String),\n",
    "        CD_RGINT Nullable(String),\n",
    "        CD_UF Nullable(String),\n",
    "        NM_CONCU Nullable(String),\n",
    "        NM_MUN Nullable(String),\n",
    "        NM_REGIA Nullable(String),\n",
    "        NM_RGI Nullable(String),\n",
    "        NM_RGINT Nullable(String),\n",
    "        NM_UF Nullable(String),\n",
    "        SIGLA_RG Nullable(String),\n",
    "        SIGLA_UF Nullable(String)),\n",
    "    type Nullable(String)))\n",
    "default_type:       \n",
    "default_expression: \n",
    "comment:            \n",
    "codec_expression:   \n",
    "ttl_expression:     \n",
    "\n",
    "3 rows in set. Elapsed: 9.143 sec. \n",
    "```\n",
    "\n",
    "Criar a tabela:\n",
    "\n",
    "```sql\n",
    "create database ibge;\n",
    "use ibge;\n",
    "CREATE TABLE br_municipios\n",
    "(\n",
    "    type String,\n",
    "    name String,\n",
    "    featureType String,\n",
    "    \n",
    "    -- Dados do município\n",
    "    cd_mun String,\n",
    "    nm_mun String,\n",
    "    area_km2 Float64,\n",
    "    \n",
    "    -- Dados da UF\n",
    "    cd_uf String,\n",
    "    nm_uf String,\n",
    "    sigla_uf String,\n",
    "    \n",
    "    -- Dados regionais\n",
    "    cd_concu Nullable(String),\n",
    "    nm_concu Nullable(String),\n",
    "    cd_regia Nullable(String),\n",
    "    nm_regia Nullable(String),\n",
    "    cd_rgi Nullable(String),\n",
    "    nm_rgi Nullable(String),\n",
    "    cd_rgint Nullable(String),\n",
    "    nm_rgint Nullable(String),\n",
    "    sigla_rg Nullable(String),\n",
    "    \n",
    "    -- Geometria\n",
    "    geometryType String,\n",
    "    geometry MultiPolygon\n",
    ")\n",
    "ENGINE = MergeTree\n",
    "ORDER BY (cd_uf, cd_mun);\n",
    "```\n",
    "\n",
    "Verificando antes de inserir.\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    type,\n",
    "    name,\n",
    "    features.type AS featureType,\n",
    "    features.properties.CD_MUN AS cd_mun,\n",
    "    features.properties.NM_MUN AS nm_mun,\n",
    "    features.properties.SIGLA_UF AS sigla_uf,\n",
    "    features.geometry.type AS geometryType\n",
    "FROM file('BR_Municipios_2024.geojson', 'JSON')\n",
    "ARRAY JOIN features\n",
    "LIMIT 5;\n",
    "```\n",
    "\n",
    "Inserindo os dados:\n",
    "```sql\n",
    "INSERT INTO br_municipios\n",
    "SELECT\n",
    "    type,\n",
    "    name,\n",
    "    features.type AS featureType,\n",
    "    \n",
    "    -- Dados do município\n",
    "    features.properties.CD_MUN AS cd_mun,\n",
    "    features.properties.NM_MUN AS nm_mun,\n",
    "    features.properties.AREA_KM2 AS area_km2,\n",
    "    \n",
    "    -- Dados da UF\n",
    "    features.properties.CD_UF AS cd_uf,\n",
    "    features.properties.NM_UF AS nm_uf,\n",
    "    features.properties.SIGLA_UF AS sigla_uf,\n",
    "    \n",
    "    -- Dados regionais\n",
    "    features.properties.CD_CONCU AS cd_concu,\n",
    "    features.properties.NM_CONCU AS nm_concu,\n",
    "    features.properties.CD_REGIA AS cd_regia,\n",
    "    features.properties.NM_REGIA AS nm_regia,\n",
    "    features.properties.CD_RGI AS cd_rgi,\n",
    "    features.properties.NM_RGI AS nm_rgi,\n",
    "    features.properties.CD_RGINT AS cd_rgint,\n",
    "    features.properties.NM_RGINT AS nm_rgint,\n",
    "    features.properties.SIGLA_RG AS sigla_rg,\n",
    "    \n",
    "    -- Geometria\n",
    "    features.geometry.type AS geometryType,\n",
    "    arrayMap(\n",
    "        poly -> arrayMap(\n",
    "            ring -> arrayMap(\n",
    "                coord -> (coord[1], coord[2]),\n",
    "                ring\n",
    "            ),\n",
    "            poly\n",
    "        ),\n",
    "        features.geometry.coordinates\n",
    "    ) AS geometry\n",
    "FROM file('BR_Municipios_2024.geojson', 'JSON')\n",
    "ARRAY JOIN features;\n",
    "```\n",
    "\n",
    "Verificar:\n",
    "\n",
    "```sql\n",
    "-- Contar registros\n",
    "SELECT count(*) FROM br_municipios;\n",
    "\n",
    "-- Verificar o tipo da geometria\n",
    "SELECT DISTINCT toTypeName(geometry) FROM br_municipios;\n",
    "\n",
    "-- Ver alguns municípios por estado\n",
    "SELECT sigla_uf, count(*) AS total_municipios\n",
    "FROM br_municipios\n",
    "GROUP BY sigla_uf\n",
    "ORDER BY sigla_uf;\n",
    "```\n",
    "\n",
    "### calculando o centroide de cada polígono\n",
    "\n",
    "```sql\n",
    "-- Função auxiliar para calcular área usando a fórmula shoelace\n",
    "CREATE FUNCTION area AS (v1, v2) -> \n",
    "    ((v1.1 * v2.2) - (v2.1 * v1.2));\n",
    "\n",
    "-- Função para calcular a área assinada do polígono\n",
    "CREATE FUNCTION signed_area AS polygon ->\n",
    "    arrayFold(\n",
    "        (acc, x) -> (\n",
    "            (acc.1) + ((((x.1).1) + ((polygon[((x.2) + 1) % (length(polygon) + 1)]).1)) \n",
    "                * area(x.1, polygon[((x.2) + 1) % (length(polygon) + 1)])),\n",
    "            (acc.2) + ((((x.1).2) + ((polygon[((x.2) + 1) % (length(polygon) + 1)]).2)) \n",
    "                * area(x.1, polygon[((x.2) + 1) % (length(polygon) + 1)])),\n",
    "            (acc.3) + area(x.1, polygon[((x.2) + 1) % (length(polygon) + 1)])\n",
    "        ),\n",
    "        arrayZip(polygon, range(1, length(polygon) + 1)),\n",
    "        (0.0, 0.0, 0.0)\n",
    "    );\n",
    "\n",
    "-- Função principal para calcular o centroide\n",
    "CREATE FUNCTION centroid AS polygon -> (\n",
    "    (signed_area(polygon).1) / ((6 * (signed_area(polygon).3)) * 0.5),\n",
    "    (signed_area(polygon).2) / ((6 * (signed_area(polygon).3)) * 0.5)\n",
    ");\n",
    "```\n",
    "\n",
    "### Calcular Centroides para Cada Município\n",
    "\n",
    "Opção 1: Adicionar Colunas à Tabela Existente\n",
    "```sql\n",
    "-- Adicionar colunas para longitude e latitude do centroide\n",
    "ALTER TABLE br_municipios \n",
    "    ADD COLUMN centroid_lon Float64,\n",
    "    ADD COLUMN centroid_lat Float64;\n",
    "\n",
    "-- Calcular e atualizar os centroides\n",
    "-- Nota: Para MultiPolygon, usamos o primeiro polígono (principal)\n",
    "ALTER TABLE br_municipios \n",
    "UPDATE \n",
    "    centroid_lon = centroid(geometry[1][1]).1,\n",
    "    centroid_lat = centroid(geometry[1][1]).2\n",
    "WHERE 1=1;\n",
    "```\n",
    "Opção 2: Consulta Direta\n",
    "```sql\n",
    "SELECT \n",
    "    cd_mun,\n",
    "    nm_mun,\n",
    "    sigla_uf,\n",
    "    \n",
    "    -- Centroide do primeiro polígono (principal)\n",
    "    centroid(geometry[1][1]).1 AS centroid_lon,\n",
    "    centroid(geometry[1][1]).2 AS centroid_lat,\n",
    "    \n",
    "    -- Ou como tupla (Point)\n",
    "    centroid(geometry[1][1]) AS centroid_point,\n",
    "    \n",
    "    area_km2\n",
    "FROM br_municipios\n",
    "ORDER BY sigla_uf, nm_mun\n",
    "LIMIT 10;\n",
    "```\n",
    "Verificar os Resultados\n",
    "```sql\n",
    "-- Ver alguns exemplos\n",
    "SELECT \n",
    "    nm_mun,\n",
    "    sigla_uf,\n",
    "    round(centroid_lon, 6) AS longitude,\n",
    "    round(centroid_lat, 6) AS latitude\n",
    "FROM br_municipios\n",
    "WHERE sigla_uf = 'RJ'\n",
    "ORDER BY nm_mun\n",
    "LIMIT 5;\n",
    "```\n",
    "Criar Vista com Centroides\n",
    "```sql\n",
    "CREATE VIEW municipios_com_centroides AS\n",
    "SELECT \n",
    "    *,\n",
    "    centroid(geometry[1][1]).1 AS centroid_lon,\n",
    "    centroid(geometry[1][1]).2 AS centroid_lat\n",
    "FROM br_municipios;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e84fe47",
   "metadata": {},
   "source": [
    "\n",
    "Carregando um arquivo CSV\n",
    "\n",
    "## População por municipio em 2025 - fonte https://sidra.ibge.gov.br/tabela/6579\n",
    "\n",
    "tabela6579.CSV\n",
    "\n",
    "file -i tabela6579.csv \n",
    "tabela6579.csv: text/plain; charset=iso-8859-1\n",
    "\n",
    "Converte para UTF8\n",
    "\n",
    "iconv -f iso-8859-1 -t utf8 tabela6579.csv > tabela6579utf8.csv\n",
    "\n",
    "Criar tabela no DB\n",
    "```sql\n",
    "Use ibge;\n",
    "CREATE TABLE IF NOT EXISTS municipio6579\n",
    "(\n",
    "    codigo String,\n",
    "    municipio String,\n",
    "    populacao UInt32\n",
    ")\n",
    "ENGINE = MergeTree()\n",
    "ORDER BY codigo;\n",
    "```\n",
    "\n",
    "### Remover o cabeçalho e importar\n",
    "\n",
    "```bash\n",
    "clickhouse-client --query=\"INSERT INTO municipios FORMAT CSV\" --format_csv_delimiter=\";\" --input_format_skip_unknown_fields=1 < <(tail -n +2 tabela6579utf8.csv)\n",
    "```\n",
    "\n",
    "Agora podemos fazer um JOIN das tabelas e descobrir a população por município.\n",
    "\n",
    "```sql\n",
    "select\n",
    "  mm.area_km2, m.populacao\n",
    "from\n",
    "  br_municipios mm inner join municipio6579 m\n",
    "  on mm.cd_mun = m.codigo;\n",
    "```\n",
    "\n",
    "\n",
    "## Tabela 8114 - Pessoas de 15 anos ou mais de idade, ocupadas na semana de referência, que se deslocava da casa para o trabalho, por tempo de deslocamento por dia e situação do domicílio - https://sidra.ibge.gov.br/Tabela/8114\n",
    "\n",
    "## Tabela 10333 - Pessoas de 10 anos ou mais de idade, ocupadas na semana de referência, que, no trabalho principal, trabalhavam fora do domicílio, por tempo habitual de deslocamento do domicílio para o trabalho principal, nível de instrução, grupo de idade e cor ou raça - https://sidra.ibge.gov.br/Tabela/10333\n",
    "\n",
    "Tabela 10333 - Pessoas de 10 anos ou mais de idade, ocupadas na semana de referência, que, no trabalho principal, trabalhavam fora do domicílio, por tempo habitual de deslocamento do domicílio para o trabalho principal, nível de instrução, grupo de idade e cor ou raça\t\t\t\t\t\t\t\t\n",
    "Cor ou raça - Total\t\t\t\t\t\t\t\t\n",
    "Nível de instrução - Total\t\t\t\t\t\t\t\t\n",
    "Grupo de idade - Total\t\t\t\t\t\t\t\t\n",
    "Ano - 2022\t\t\t\t\t\t\t\t\n",
    "Variável - Pessoas de 10 anos ou mais de idade, ocupadas na semana de referência, que, no trabalho principal, trabalhavam fora do domicílio (Pessoas)\t\t\t\t\t\t\t\t\n",
    "\n",
    "*Tempo habitual de deslocamento do domicílio para o trabalho principal*\n",
    "\n",
    "```sql\n",
    "Use ibge;\n",
    "CREATE TABLE IF NOT EXISTS casatrabalho10333\n",
    "(\n",
    "    codigo String,\n",
    "    municipio String,\n",
    "    ate5min UInt32,\n",
    "    d6ate15m UInt32,\n",
    "    d15ate30m UInt32,\n",
    "    d30mate1h UInt32,\n",
    "    d1ate2h UInt32,\n",
    "    d2ate4h UInt32,\n",
    "    m4h UInt32\n",
    ")\n",
    "ENGINE = MergeTree()\n",
    "ORDER BY codigo;\n",
    "```\n",
    "\n",
    "O arquivo do IBGE possui \"-\" no lugar de valores nulos. Para carregar no banco de dados precisamos substituir os \"-\" por \"0\" (zero), mas apenas quando o traço for precedido de \";\".\n",
    "\n",
    "```bash\n",
    "sed 's/;-/;0/g' tabela10333utf8.csv > tabela10333utf8v2.csv\n",
    "```\n",
    "\n",
    "Removi a última linha manualmente, que possui um texto descritivo.\n",
    "\n",
    "### Remover o cabeçalho e importar\n",
    "\n",
    "```bash\n",
    "clickhouse-client --query=\"INSERT INTO ibge.casatrabalho10333 FORMAT CSV\" --format_csv_delimiter=\";\" --input_format_skip_unknown_fields=1 < <(tail -n +2 tabela10333utf8v2.csv)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe0c3c",
   "metadata": {},
   "source": [
    "### Podemos montar algumas distribuições\n",
    "\n",
    "#### qtd de pessoas vs qtd de horas até o trabalho\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT\n",
    "    m.populacao,\n",
    "    ct.ate5min\n",
    "FROM municipio6579 m inner join casatrabalho10333 ct on ct.codigo = m.codigo\n",
    "ORDER BY m.populacao\n",
    "LIMIT 30;\n",
    "```\n",
    "\n",
    "#### area_km2 vs pop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535fdc2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ServerException",
     "evalue": "Code: 60.\nDB::Exception: Unknown table expression identifier 'municipio6579' in scope SELECT m.populacao, ct.ate5min, ct.d6ate15m FROM municipio6579 AS m INNER JOIN casatrabalho10333 AS ct ON ct.codigo = m.codigo ORDER BY m.populacao ASC. Stack trace:\n\n0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000001515d85f\n1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cdc064e\n2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cdc0040\n3. DB::Exception::Exception<String const&, String>(int, FormatStringHelperImpl<std::type_identity<String const&>::type, std::type_identity<String>::type>, String const&, String&&) @ 0x000000000dea552b\n4. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000193589fa\n5. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001935286a\n6. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000019351e9c\n7. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>&) @ 0x00000000193a9763\n8. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.3622699265643270361) @ 0x0000000019f1223b\n9. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000019f1012a\n10. std::unique_ptr<DB::IInterpreter, std::default_delete<DB::IInterpreter>> std::__function::__policy_func<std::unique_ptr<DB::IInterpreter, std::default_delete<DB::IInterpreter>> (DB::InterpreterFactory::Arguments const&)>::__call_func[abi:ne210105]<DB::registerInterpreterSelectQueryAnalyzer(DB::InterpreterFactory&)::$_0>(std::__function::__policy_storage const*, DB::InterpreterFactory::Arguments const&) (.llvm.3622699265643270361) @ 0x0000000019f137a2\n11. DB::InterpreterFactory::get(std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::Context>, DB::SelectQueryOptions const&) @ 0x0000000019e842fc\n12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>, std::function<void ()>, DB::QueryResultDetails&) @ 0x000000001a2de14a\n13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x000000001a2d8cbb\n14. DB::TCPHandler::runImpl() @ 0x000000001ba4c5c0\n15. DB::TCPHandler::run() @ 0x000000001ba6ded9\n16. Poco::Net::TCPServerConnection::start() @ 0x0000000020d53247\n17. Poco::Net::TCPServerDispatcher::run() @ 0x0000000020d536d9\n18. Poco::PooledThread::run() @ 0x0000000020d16d47\n19. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000020d15281\n20. ? @ 0x000000000009caa4\n21. clone @ 0x0000000000129a34\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServerException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      9\u001b[39m query = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33mSELECT\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m    m.populacao,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33mORDER BY m.populacao\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Executar query e carregar em DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m df_q = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Garantir colunas numéricas e computar \"até 15 min\" (até 5 + 6-15)\u001b[39;00m\n\u001b[32m     23\u001b[39m df_q[\u001b[33m'\u001b[39m\u001b[33mpopulacao\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(df_q[\u001b[33m'\u001b[39m\u001b[33mpopulacao\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/clickhouse_driver/client.py:491\u001b[39m, in \u001b[36mClient.query_dataframe\u001b[39m\u001b[34m(self, query, params, external_tables, query_id, settings, replace_nonwords)\u001b[39m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mExtras for NumPy must be installed\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m data, columns = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumnar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexternal_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexternal_tables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msettings\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m columns = [name \u001b[38;5;28;01mfor\u001b[39;00m name, type_ \u001b[38;5;129;01min\u001b[39;00m columns]\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m replace_nonwords:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/clickhouse_driver/client.py:382\u001b[39m, in \u001b[36mClient.execute\u001b[39m\u001b[34m(self, query, params, with_column_types, external_tables, query_id, settings, types_check, columnar)\u001b[39m\n\u001b[32m    376\u001b[39m     rv = \u001b[38;5;28mself\u001b[39m.process_insert_query(\n\u001b[32m    377\u001b[39m         query, params, external_tables=external_tables,\n\u001b[32m    378\u001b[39m         query_id=query_id, types_check=types_check,\n\u001b[32m    379\u001b[39m         columnar=columnar\n\u001b[32m    380\u001b[39m     )\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     rv = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess_ordinary_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexternal_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexternal_tables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes_check\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumnar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumnar\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[38;5;28mself\u001b[39m.last_query.store_elapsed(time() - start_time)\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/clickhouse_driver/client.py:580\u001b[39m, in \u001b[36mClient.process_ordinary_query\u001b[39m\u001b[34m(self, query, params, with_column_types, external_tables, query_id, types_check, columnar)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28mself\u001b[39m.connection.send_query(query, query_id=query_id, params=params)\n\u001b[32m    578\u001b[39m \u001b[38;5;28mself\u001b[39m.connection.send_external_tables(external_tables,\n\u001b[32m    579\u001b[39m                                      types_check=types_check)\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_column_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcolumnar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumnar\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/clickhouse_driver/client.py:212\u001b[39m, in \u001b[36mClient.receive_result\u001b[39m\u001b[34m(self, with_column_types, progress, columnar)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    209\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.query_result_cls(\n\u001b[32m    210\u001b[39m         gen, with_column_types=with_column_types, columnar=columnar\n\u001b[32m    211\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/clickhouse_driver/result.py:50\u001b[39m, in \u001b[36mQueryResult.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     46\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[33;03m    :return: stored query result.\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpacket\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpacket_generator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/clickhouse_driver/client.py:228\u001b[39m, in \u001b[36mClient.packet_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m         packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m packet:\n\u001b[32m    230\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/clickhouse_driver/client.py:245\u001b[39m, in \u001b[36mClient.receive_packet\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    242\u001b[39m packet = \u001b[38;5;28mself\u001b[39m.connection.receive_packet()\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m packet.type == ServerPacketTypes.EXCEPTION:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m packet.exception\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m packet.type == ServerPacketTypes.PROGRESS:\n\u001b[32m    248\u001b[39m     \u001b[38;5;28mself\u001b[39m.last_query.store_progress(packet.progress)\n",
      "\u001b[31mServerException\u001b[39m: Code: 60.\nDB::Exception: Unknown table expression identifier 'municipio6579' in scope SELECT m.populacao, ct.ate5min, ct.d6ate15m FROM municipio6579 AS m INNER JOIN casatrabalho10333 AS ct ON ct.codigo = m.codigo ORDER BY m.populacao ASC. Stack trace:\n\n0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000001515d85f\n1. DB::Exception::Exception(String&&, int, String, bool) @ 0x000000000cdc064e\n2. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x000000000cdc0040\n3. DB::Exception::Exception<String const&, String>(int, FormatStringHelperImpl<std::type_identity<String const&>::type, std::type_identity<String>::type>, String const&, String&&) @ 0x000000000dea552b\n4. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000193589fa\n5. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x000000001935286a\n6. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x0000000019351e9c\n7. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>&) @ 0x00000000193a9763\n8. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.3622699265643270361) @ 0x0000000019f1223b\n9. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000019f1012a\n10. std::unique_ptr<DB::IInterpreter, std::default_delete<DB::IInterpreter>> std::__function::__policy_func<std::unique_ptr<DB::IInterpreter, std::default_delete<DB::IInterpreter>> (DB::InterpreterFactory::Arguments const&)>::__call_func[abi:ne210105]<DB::registerInterpreterSelectQueryAnalyzer(DB::InterpreterFactory&)::$_0>(std::__function::__policy_storage const*, DB::InterpreterFactory::Arguments const&) (.llvm.3622699265643270361) @ 0x0000000019f137a2\n11. DB::InterpreterFactory::get(std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::Context>, DB::SelectQueryOptions const&) @ 0x0000000019e842fc\n12. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, std::unique_ptr<DB::ReadBuffer, std::default_delete<DB::ReadBuffer>>&, std::shared_ptr<DB::IAST>&, std::shared_ptr<DB::ImplicitTransactionControlExecutor>, std::function<void ()>, DB::QueryResultDetails&) @ 0x000000001a2de14a\n13. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x000000001a2d8cbb\n14. DB::TCPHandler::runImpl() @ 0x000000001ba4c5c0\n15. DB::TCPHandler::run() @ 0x000000001ba6ded9\n16. Poco::Net::TCPServerConnection::start() @ 0x0000000020d53247\n17. Poco::Net::TCPServerDispatcher::run() @ 0x0000000020d536d9\n18. Poco::PooledThread::run() @ 0x0000000020d16d47\n19. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000020d15281\n20. ? @ 0x000000000009caa4\n21. clone @ 0x0000000000129a34\n"
     ]
    }
   ],
   "source": [
    "from clickhouse_driver import Client\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurar conexão com ClickHouse (ajuste host, user, password conforme seu ambiente)\n",
    "client = Client(host='localhost', user='default', password='785498')\n",
    "\n",
    "# Query SQL\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    m.populacao,\n",
    "    ct.ate5min,\n",
    "    ct.d6ate15m\n",
    "FROM municipio6579 m\n",
    "INNER JOIN casatrabalho10333 ct ON ct.codigo = m.codigo\n",
    "ORDER BY m.populacao\n",
    "\"\"\"\n",
    "\n",
    "# Executar query e carregar em DataFrame\n",
    "df_q = client.query_dataframe(query)\n",
    "\n",
    "# Garantir colunas numéricas e computar \"até 15 min\" (até 5 + 6-15)\n",
    "df_q['populacao'] = pd.to_numeric(df_q['populacao'], errors='coerce')\n",
    "df_q['ate5min'] = pd.to_numeric(df_q.get('ate5min', 0), errors='coerce').fillna(0)\n",
    "df_q['d6ate15m'] = pd.to_numeric(df_q.get('d6ate15m', 0), errors='coerce').fillna(0)\n",
    "df_q['ate_ate15min'] = df_q['ate5min'] + df_q['d6ate15m']\n",
    "df_q = df_q.dropna(subset=['populacao', 'ate_ate15min'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.scatter(df_q['populacao'], df_q['ate_ate15min'], alpha=0.6, s=30)\n",
    "plt.xscale('log')  # opcional: melhora visualização quando há muitos municípios pequenos\n",
    "plt.xlabel('População do município')\n",
    "plt.ylabel('Pessoas que levam até 15 minutos (ate5min + d6ate15m)')\n",
    "plt.title('Dispersão: População vs Pessoas até 15 min')\n",
    "plt.grid(True, which='both', ls='--', alpha=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
